{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG arrhythmia classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameter for Image Data agumentation to the traing data\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data agumentation to the testing data\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data and performing data agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n",
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#performing data agumentation to train data\n",
    "x_train=train_datagen.flow_from_directory(directory=r'D:\\Emerging Methods for Early Detection of Forest Fires\\Dataset\\train_set'\n",
    "                                          ,target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "#performing data agumentation to test data\n",
    "x_test=test_datagen.flow_from_directory(directory=r'D:\\Emerging Methods for Early Detection of Forest Fires\\Dataset\\test_set'\n",
    "                                        ,target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forest': 0, 'with fire': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)#checking the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 281, 1: 155})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model=Sequential()\n",
    "# adding model layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))#convolutional layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #MaxPooling2D-for downsampling the input\n",
    "\n",
    "# model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())#flatten the dimension of the image\n",
    "model.add(Dense(32))#deeply connected neural network layers.\n",
    "model.add(Dense(2,activation='softmax'))#output layer with 6 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                984096    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 985,058\n",
      "Trainable params: 985,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#summary of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.3945 - accuracy: 0.6904 - val_loss: 0.1972 - val_accuracy: 0.9174\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.3055 - accuracy: 0.8853 - val_loss: 0.1136 - val_accuracy: 0.9752\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1862 - accuracy: 0.9312 - val_loss: 0.0737 - val_accuracy: 0.9835\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.1586 - accuracy: 0.9404 - val_loss: 0.0661 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.1431 - accuracy: 0.9450 - val_loss: 0.0514 - val_accuracy: 0.9917\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 35s 3s/step - loss: 0.1561 - accuracy: 0.9289 - val_loss: 0.0636 - val_accuracy: 0.9669\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 34s 3s/step - loss: 0.1606 - accuracy: 0.9289 - val_loss: 0.0754 - val_accuracy: 0.9504\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 35s 3s/step - loss: 0.1529 - accuracy: 0.9312 - val_loss: 0.0499 - val_accuracy: 0.9752\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.1213 - accuracy: 0.9541 - val_loss: 0.0312 - val_accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.1235 - accuracy: 0.9472 - val_loss: 0.0448 - val_accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c541aa7c70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,steps_per_epoch=len(x_train),validation_data=x_test,validation_steps=len(x_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit_generator(x_train,epochs=10,validation_data=x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('forest.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model = load_model(\"forest.h5\") #loading the model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(r\"D:\\Emerging Methods for Early Detection of Forest Fires\\Dataset\\train_set\\with fire\\with fire (2).jpeg\",target_size= (64,64))#loading of the image\n",
    "x = image.img_to_array(img)#image to array\n",
    "x = np.expand_dims(x,axis = 0)#changing the shape\n",
    "#pred = model.predict_classes(x)#predicting the classes\n",
    "#pred\n",
    "preds=model.predict(x)\n",
    "pred=np.argmax(preds,axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With Fire'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['Forest','With Fire']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(r\"D:\\Emerging Methods for Early Detection of Forest Fires\\Dataset\\train_set\\with fire\\with fire (12).jpg\",target_size= (64,64))#loading of the image\n",
    "x = image.img_to_array(img)#image to array\n",
    "x = np.expand_dims(x,axis = 0)#changing the shape\n",
    "#pred = model.predict_classes(x)#predicting the classes\n",
    "#pred\n",
    "preds=model.predict(x)\n",
    "pred=np.argmax(preds,axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With Fire'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['Forest','With Fire']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Forest'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(r\"D:\\Emerging Methods for Early Detection of Forest Fires\\Data\\Test_Data\\Non_Fire\\NF_15.jpg\",target_size= (64,64))#loading of the image\n",
    "x = image.img_to_array(img)#image to array\n",
    "x = np.expand_dims(x,axis = 0)#changing the shape\n",
    "preds=model.predict(x)\n",
    "pred=np.argmax(preds,axis=1)\n",
    "index=['Forest','With Fire']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
